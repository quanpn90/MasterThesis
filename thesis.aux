\relax 
\citation{devlin14}
\citation{Bengio2003}
\citation{sutskever14}
\citation{hutchins07}
\citation{weaver49}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c:intro}{{1}{1}}
\citation{Brown:1993:MSM}
\citation{Koehn:2003:SMT,och03,Liang:2006:EDA,koehn2007moses,chiang07hiero,dyer10cdec,cer10phrasal}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces {\bf  Machine translation} (MT) -- a general setup of MT. Systems build translation models from parallel corpora to translate new unseen sentences, e.g., ``She loves cute cats''.}}{2}}
\newlabel{f:mt}{{1.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces {\bf  Phrase-based machine translation} (MT) -- example of how phrase-based MT systems translate a source sentence ``She loves cute cats'' into a target sentence ``Elle aime les chats mignons'': sentences are split into chunks and phrases are translated. }}{2}}
\newlabel{f:phrase_mt}{{1.2}{2}}
\citation{Bengio2003}
\citation{kenlm}
\citation{schwenk07,vaswani13decode,luong15nlm}
\citation{Schwenk12continuous,devlin14}
\citation{devlin14}
\citation{devlin14}
\citation{Bengio2003}
\citation{devlin14}
\citation{Bengio2003}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces {\bf  Source-conditioned neural language model} (NLM) -- example of a source-conditioned NLM proposed by \citet  {devlin14}. To evaluate a how likely a next word ``rive'' is, the model not only relies on previous target words (context) ``promenade le long de la'' as in traditional NLMs \cite  {Bengio2003}, but also utilizes source context ``along the South Bank'' to lower uncertainty in its prediction. }}{3}}
\newlabel{f:nnjm}{{1.3}{3}}
\citation{kal13,sutskever14,cho14}
\citation{luong15}
\citation{jean15,luong15attn,sennrich16mono}
\citation{jean15wmt,luong16}
\citation{sutskever14}
\citation{sutskever14}
\citation{Koehn:2003:SMT}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces {\bf  Neural machine translation} -- example of a deep recurrent architecture proposed by \citet  {sutskever14} for translating a source sentence ``I am a student'' into a target sentence ``Je suis \'{e}tudiant''. Here, ``\texttt  {\_}'' marks the end of a sentence. }}{4}}
\newlabel{f:nmt}{{1.4}{4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c:review}{{2}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Overview}{6}}
\newlabel{eq:lm1}{{2.1}{6}}
\citation{papineni2002bleu}
\citation{Rosenfeld:2000}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Evaluation Metrics}{7}}
\newlabel{eq:ppl}{{2.2}{7}}
\citation{kingsley1932selective}
\citation{kneser1995improved}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Prominent approaches in Language Models}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}$N$-gram statistical language models}{8}}
\newlabel{eq:markov}{{2.3}{8}}
\newlabel{eq:ngramMLE}{{2.4}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Interpolated Knesey-Ney smoothing}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Structured language models}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Class based language models}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Maximum Entropy Language models}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Neural Network Language Models}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Feed-forward variations}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Recurrent Neural Network variations}{9}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Neural Network Language Models}{10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c:nnlm}{{3}{10}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Convolutional Neural Network}{11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c:cnn}{{4}{11}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experiments}{12}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c:exp}{{5}{12}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Inside the Convolutional layer}{13}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c:analysis}{{6}{13}}
\bibstyle{plainnat}
\bibdata{thesis}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{14}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c:conc}{{7}{14}}
\bibcite{Bengio2003}{{1}{2003}{{Bengio et~al.}}{{Bengio, Ducharme, Vincent, and Janvin}}}
\bibcite{Brown:1993:MSM}{{2}{1993}{{Brown et~al.}}{{Brown, Pietra, Pietra, and Mercer}}}
\bibcite{cer10phrasal}{{3}{2010}{{Cer et~al.}}{{Cer, Galley, Jurafsky, and Manning}}}
\bibcite{chiang07hiero}{{4}{2007}{{Chiang}}{{}}}
\bibcite{cho14}{{5}{2014}{{Cho et~al.}}{{Cho, van Merrienboer, Gulcehre, Bougares, Schwenk, and Bengio}}}
\bibcite{devlin14}{{6}{2014}{{Devlin et~al.}}{{Devlin, Zbib, Huang, Lamar, Schwartz, and Makhoul}}}
\bibcite{dyer10cdec}{{7}{2010}{{Dyer et~al.}}{{Dyer, Weese, Setiawan, Lopez, Ture, Eidelman, Ganitkevitch, Blunsom, and Resnik}}}
\bibcite{kenlm}{{8}{2011}{{Heafield}}{{}}}
\bibcite{hutchins07}{{9}{2007}{{Hutchins}}{{}}}
\bibcite{jean15}{{10}{2015{}}{{Jean et~al.}}{{Jean, Cho, Memisevic, and Bengio}}}
\bibcite{jean15wmt}{{11}{2015{}}{{Jean et~al.}}{{Jean, Firat, Cho, Memisevic, and Bengio}}}
\bibcite{kal13}{{12}{2013}{{Kalchbrenner and Blunsom}}{{}}}
\bibcite{kingsley1932selective}{{13}{1932}{{Kingsley}}{{}}}
\bibcite{kneser1995improved}{{14}{1995}{{Kneser and Ney}}{{}}}
\bibcite{Koehn:2003:SMT}{{15}{2003}{{Koehn et~al.}}{{Koehn, Och, and Marcu}}}
\bibcite{koehn2007moses}{{16}{2007}{{Koehn et~al.}}{{Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, et~al.}}}
\bibcite{Liang:2006:EDA}{{17}{2006}{{Liang et~al.}}{{Liang, Bouchard-C\^{o}t{\'e}, Klein, and Taskar}}}
\bibcite{luong16}{{18}{2016}{{Luong and Manning}}{{}}}
\bibcite{luong15nlm}{{19}{2015{}}{{Luong et~al.}}{{Luong, Kayser, and Manning}}}
\bibcite{luong15attn}{{20}{2015{}}{{Luong et~al.}}{{Luong, Pham, and Manning}}}
\bibcite{luong15}{{21}{2015{}}{{Luong et~al.}}{{Luong, Sutskever, Le, Vinyals, and Zaremba}}}
\bibcite{och03}{{22}{2003}{{Och and Ney}}{{}}}
\bibcite{papineni2002bleu}{{23}{2002}{{Papineni et~al.}}{{Papineni, Roukos, Ward, and Zhu}}}
\bibcite{Rosenfeld:2000}{{24}{2000}{{Rosenfeld}}{{}}}
\bibcite{schwenk07}{{25}{2007}{{Schwenk}}{{}}}
\bibcite{Schwenk12continuous}{{26}{2012}{{Schwenk}}{{}}}
\bibcite{sennrich16mono}{{27}{2016}{{Sennrich et~al.}}{{Sennrich, Haddow, and Birch}}}
\bibcite{sutskever14}{{28}{2014}{{Sutskever et~al.}}{{Sutskever, Vinyals, and Le}}}
\bibcite{vaswani13decode}{{29}{2013}{{Vaswani et~al.}}{{Vaswani, Zhao, Fossum, and Chiang}}}
\bibcite{weaver49}{{30}{1949}{{Weaver}}{{}}}
