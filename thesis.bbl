\begin{thebibliography}{64}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdel-Hamid et~al.(2012)Abdel-Hamid, Mohamed, Jiang, and
  Penn]{abdel2012applying}
Ossama Abdel-Hamid, Abdel-rahman Mohamed, Hui Jiang, and Gerald Penn.
\newblock Applying convolutional neural networks concepts to hybrid nn-hmm
  model for speech recognition.
\newblock In \emph{2012 IEEE international conference on Acoustics, speech and
  signal processing (ICASSP)}, pages 4277--4280. IEEE, 2012.

\bibitem[Bengio et~al.(1994)Bengio, Simard, and Frasconi]{bengio1994learning}
Yoshua Bengio, Patrice Simard, and Paolo Frasconi.
\newblock Learning long-term dependencies with gradient descent is difficult.
\newblock \emph{IEEE transactions on neural networks}, 5\penalty0 (2):\penalty0
  157--166, 1994.

\bibitem[Bengio et~al.(2003)Bengio, Ducharme, Vincent, and
  Jauvin]{bengio2003neural}
Yoshua Bengio, R{\'e}jean Ducharme, Pascal Vincent, and Christian Jauvin.
\newblock A neural probabilistic language model.
\newblock \emph{journal of machine learning research}, 3\penalty0
  (Feb):\penalty0 1137--1155, 2003.

\bibitem[Bengio et~al.(2006)Bengio, Schwenk, Sen{\'e}cal, Morin, and
  Gauvain]{bengio2006neural}
Yoshua Bengio, Holger Schwenk, Jean-S{\'e}bastien Sen{\'e}cal, Fr{\'e}deric
  Morin, and Jean-Luc Gauvain.
\newblock Neural probabilistic language models.
\newblock In \emph{Innovations in Machine Learning}, pages 137--186. Springer,
  2006.

\bibitem[Bengio et~al.(2013)Bengio, Boulanger-Lewandowski, and
  Pascanu]{bengio2013advances}
Yoshua Bengio, Nicolas Boulanger-Lewandowski, and Razvan Pascanu.
\newblock Advances in optimizing recurrent networks.
\newblock In \emph{2013 IEEE International Conference on Acoustics, Speech and
  Signal Processing}, pages 8624--8628. IEEE, 2013.

\bibitem[Bojar et~al.(2015)Bojar, Chatterjee, Federmann, Haddow, Huck, Hokamp,
  Koehn, Logacheva, Monz, Negri, Post, Scarton, Specia, and
  Turchi]{bojar-EtAl:2015:WMT}
Ond\v{r}ej Bojar, Rajen Chatterjee, Christian Federmann, Barry Haddow, Matthias
  Huck, Chris Hokamp, Philipp Koehn, Varvara Logacheva, Christof Monz, Matteo
  Negri, Matt Post, Carolina Scarton, Lucia Specia, and Marco Turchi.
\newblock Findings of the 2015 workshop on statistical machine translation.
\newblock In \emph{Proceedings of the Tenth Workshop on Statistical Machine
  Translation}, pages 1--46, Lisbon, Portugal, September 2015. Association for
  Computational Linguistics.
\newblock URL \url{http://aclweb.org/anthology/W15-3001}.

\bibitem[Brown et~al.(1992)Brown, Desouza, Mercer, Pietra, and
  Lai]{brown1992class}
Peter~F Brown, Peter~V Desouza, Robert~L Mercer, Vincent J~Della Pietra, and
  Jenifer~C Lai.
\newblock Class-based n-gram models of natural language.
\newblock \emph{Computational linguistics}, 18\penalty0 (4):\penalty0 467--479,
  1992.

\bibitem[Chelba and Jelinek(2000)]{chelba2000structured}
Ciprian Chelba and Frederick Jelinek.
\newblock Structured language modeling.
\newblock \emph{Computer Speech \& Language}, 14\penalty0 (4):\penalty0
  283--332, 2000.

\bibitem[Chen and Goodman(1999)]{chen1999empirical}
Stanley~F Chen and Joshua Goodman.
\newblock An empirical study of smoothing techniques for language modeling.
\newblock \emph{Computer Speech \& Language}, 13\penalty0 (4):\penalty0
  359--394, 1999.

\bibitem[Cho et~al.(2014)Cho, Van~Merri{\"e}nboer, Gulcehre, Bahdanau,
  Bougares, Schwenk, and Bengio]{cho2014learning}
Kyunghyun Cho, Bart Van~Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock \emph{arXiv preprint arXiv:1406.1078}, 2014.

\bibitem[Collobert et~al.(2011)Collobert, Weston, Bottou, Karlen, Kavukcuoglu,
  and Kuksa]{collobert2011natural}
Ronan Collobert, Jason Weston, L{\'e}on Bottou, Michael Karlen, Koray
  Kavukcuoglu, and Pavel Kuksa.
\newblock Natural language processing (almost) from scratch.
\newblock \emph{The Journal of Machine Learning Research}, 12:\penalty0
  2493--2537, 2011.

\bibitem[Devlin et~al.(2014)Devlin, Zbib, Huang, Lamar, Schwartz, and
  Makhoul]{devlin2014fast}
Jacob Devlin, Rabih Zbib, Zhongqiang Huang, Thomas Lamar, Richard~M Schwartz,
  and John Makhoul.
\newblock Fast and robust neural network joint models for statistical machine
  translation.
\newblock In \emph{ACL (1)}, pages 1370--1380. Citeseer, 2014.

\bibitem[Elman(1990)]{elman1990finding}
Jeffrey~L Elman.
\newblock Finding structure in time.
\newblock \emph{Cognitive science}, 14\penalty0 (2):\penalty0 179--211, 1990.

\bibitem[Federico et~al.(2008)Federico, Bertoldi, and
  Cettolo]{federico2008irstlm}
Marcello Federico, Nicola Bertoldi, and Mauro Cettolo.
\newblock Irstlm: an open source toolkit for handling large scale language
  models.
\newblock In \emph{Interspeech}, pages 1618--1621, 2008.

\bibitem[Filimonov and Harper(2009)]{filimonov2009joint}
Denis Filimonov and Mary Harper.
\newblock A joint language model with fine-grain syntactic tags.
\newblock In \emph{Proceedings of the 2009 Conference on Empirical Methods in
  Natural Language Processing: Volume 3-Volume 3}, pages 1114--1123.
  Association for Computational Linguistics, 2009.

\bibitem[Fukushima(1980)]{fukushima1980neocognitron}
Kunihiko Fukushima.
\newblock Neocognitron: A self-organizing neural network model for a mechanism
  of pattern recognition unaffected by shift in position.
\newblock \emph{Biological cybernetics}, 36\penalty0 (4):\penalty0 193--202,
  1980.

\bibitem[Graves and Schmidhuber(2005)]{graves2005framewise}
Alex Graves and J{\"u}rgen Schmidhuber.
\newblock Framewise phoneme classification with bidirectional lstm and other
  neural network architectures.
\newblock \emph{Neural Networks}, 18\penalty0 (5):\penalty0 602--610, 2005.

\bibitem[Gu et~al.(2015)Gu, Wang, Kuen, Ma, Shahroudy, Shuai, Liu, Wang, and
  Wang]{Gu:etal:2015}
Jiuxiang Gu, Zhenhua Wang, Jason Kuen, Lianyang Ma, Amir Shahroudy, Bing Shuai,
  Ting Liu, Xingxing Wang, and Gang Wang.
\newblock Recent advances in convolutional neural networks.
\newblock \emph{CoRR}, abs/1512.07108, 2015.

\bibitem[Hai~Son et~al.(2011)Hai~Son, Oparin, Allauzen, Gauvain, and
  Yvon]{le2011structured}
Le~Hai~Son, Ilya Oparin, Alexandre Allauzen, Jean-Luc Gauvain, and
  Fran{\c{c}}ois Yvon.
\newblock Structured output layer neural network language model.
\newblock In \emph{Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE
  International Conference on}, pages 5524--5527. IEEE, 2011.

\bibitem[Hai~Son et~al.(2012)Hai~Son, Allauzen, and Yvon]{hai2012measuring}
Le~Hai~Son, Alexandre Allauzen, and Fran{\c{c}}ois Yvon.
\newblock Measuring the influence of long range dependencies with neural
  network language models.
\newblock In \emph{Proceedings of the NAACL-HLT 2012 Workshop: Will We Ever
  Really Replace the N-gram Model? On the Future of Language Modeling for HLT},
  pages 1--10. Association for Computational Linguistics, 2012.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{kaiming2015resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock \emph{arXiv preprint arXiv:1512.03385}, 2015.

\bibitem[Heafield(2011)]{heafield2011kenlm}
Kenneth Heafield.
\newblock Kenlm: Faster and smaller language model queries.
\newblock In \emph{Proceedings of the Sixth Workshop on Statistical Machine
  Translation}, pages 187--197. Association for Computational Linguistics,
  2011.

\bibitem[Hinton et~al.(2012)Hinton, Srivastava, Krizhevsky, Sutskever, and
  Salakhutdinov]{hinton2012dropout}
Geoffrey~E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and
  Ruslan Salakhutdinov.
\newblock Improving neural networks by preventing co-adaptation of feature
  detectors.
\newblock \emph{CoRR}, abs/1207.0580, 2012.
\newblock URL \url{http://arxiv.org/abs/1207.0580}.

\bibitem[Hochreiter and Schmidhuber(1997)]{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Hu et~al.(2014)Hu, Lu, Li, and Chen]{hu2014convolutional}
Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen.
\newblock Convolutional neural network architectures for matching natural
  language sentences.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2042--2050, 2014.

\bibitem[Ioffe and Szegedy(2015)]{DBLP:journals/corr/IoffeS15}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Kalchbrenner et~al.(2014)Kalchbrenner, Grefenstette, and
  Blunsom]{Kalchbrenner2014conv}
Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom.
\newblock A convolutional neural network for modelling sentences.
\newblock In \emph{Proceedings of the 52nd Annual Meeting of the Association
  for Computational Linguistics, {ACL} 2014, June 22-27, 2014, Baltimore, MD,
  USA, Volume 1: Long Papers}, pages 655--665, 2014.
\newblock URL \url{http://aclweb.org/anthology/P/P14/P14-1062.pdf}.

\bibitem[Kim(2014)]{kim2014sentence}
Yoon Kim.
\newblock Convolutional neural networks for sentence classification.
\newblock \emph{arXiv preprint arXiv:1408.5882}, 2014.

\bibitem[Kingsley(1932)]{kingsley1932selective}
Zipf~George Kingsley.
\newblock Selective studies and the principle of relative frequency in
  language, 1932.

\bibitem[Kneser and Ney(1995)]{kneser1995improved}
Reinhard Kneser and Hermann Ney.
\newblock Improved backing-off for m-gram language modeling.
\newblock In \emph{Acoustics, Speech, and Signal Processing, 1995. ICASSP-95.,
  1995 International Conference on}, volume~1, pages 181--184. IEEE, 1995.

\bibitem[Koehn et~al.(2007)Koehn, Hoang, Birch, Callison-Burch, Federico,
  Bertoldi, Cowan, Shen, Moran, Zens, et~al.]{koehn2007moses}
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello
  Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard
  Zens, et~al.
\newblock Moses: Open source toolkit for statistical machine translation.
\newblock In \emph{Proceedings of the 45th annual meeting of the ACL on
  interactive poster and demonstration sessions}, pages 177--180. Association
  for Computational Linguistics, 2007.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  1097--1105, 2012.

\bibitem[Le et~al.(2015)Le, Jaitly, and Hinton]{le2015simple}
Quoc~V Le, Navdeep Jaitly, and Geoffrey~E Hinton.
\newblock A simple way to initialize recurrent networks of rectified linear
  units.
\newblock \emph{arXiv preprint arXiv:1504.00941}, 2015.

\bibitem[Le~Cun et~al.(1990)Le~Cun, Denker, Henderson, Howard, Hubbard, and
  Jackel]{le1990handwritten}
B~Boser Le~Cun, John~S Denker, D~Henderson, Richard~E Howard, W~Hubbard, and
  Lawrence~D Jackel.
\newblock Handwritten digit recognition with a back-propagation network.
\newblock In \emph{Advances in neural information processing systems}.
  Citeseer, 1990.

\bibitem[LeCun and Bengio(1995)]{lecun1995convolutional}
Yann LeCun and Yoshua Bengio.
\newblock Convolutional networks for images, speech, and time series.
\newblock \emph{The handbook of brain theory and neural networks},
  3361\penalty0 (10):\penalty0 1995, 1995.

\bibitem[Lin et~al.(2013)Lin, Chen, and Yan]{lin2013network}
Min Lin, Qiang Chen, and Shuicheng Yan.
\newblock Network in network.
\newblock \emph{arXiv preprint arXiv:1312.4400}, 2013.

\bibitem[Martens and Sutskever(2011)]{martens2011learning}
James Martens and Ilya Sutskever.
\newblock Learning recurrent neural networks with hessian-free optimization.
\newblock In \emph{Proceedings of the 28th International Conference on Machine
  Learning (ICML-11)}, pages 1033--1040, 2011.

\bibitem[Mikolov et~al.(2010)Mikolov, Karafi{\'a}t, Burget, Cernock{\`y}, and
  Khudanpur]{mikolov2010recurrent}
Tomas Mikolov, Martin Karafi{\'a}t, Lukas Burget, Jan Cernock{\`y}, and Sanjeev
  Khudanpur.
\newblock Recurrent neural network based language model.
\newblock In \emph{INTERSPEECH}, volume~2, page~3, 2010.

\bibitem[Mikolov et~al.(2011)Mikolov, Kombrink, Burget, {\v{C}}ernock{\`y}, and
  Khudanpur]{mikolov2011extensions}
Tom{\'a}{\v{s}} Mikolov, Stefan Kombrink, Luk{\'a}{\v{s}} Burget, Jan~Honza
  {\v{C}}ernock{\`y}, and Sanjeev Khudanpur.
\newblock Extensions of recurrent neural network language model.
\newblock In \emph{Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE
  International Conference on}, pages 5528--5531. IEEE, 2011.

\bibitem[Mikolov et~al.(2014)Mikolov, Joulin, Chopra, Mathieu, and
  Ranzato]{mikolov2014learning}
Tomas Mikolov, Armand Joulin, Sumit Chopra, Michael Mathieu, and Marc'Aurelio
  Ranzato.
\newblock Learning longer memory in recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1412.7753}, 2014.

\bibitem[Ney et~al.(1994)Ney, Essen, and Kneser]{ney1994structuring}
Hermann Ney, Ute Essen, and Reinhard Kneser.
\newblock On structuring probabilistic dependences in stochastic language
  modelling.
\newblock \emph{Computer Speech \& Language}, 8\penalty0 (1):\penalty0 1--38,
  1994.

\bibitem[Nguyen and Grishman(2015)]{nguyen2015relation}
Thien~Huu Nguyen and Ralph Grishman.
\newblock Relation extraction: Perspective from convolutional neural networks.
\newblock In \emph{Proceedings of NAACL-HLT}, pages 39--48, 2015.

\bibitem[Niesler and Woodland(1996)]{niesler1996variable}
Thomas~R Niesler and Philip~C Woodland.
\newblock A variable-length category-based n-gram language model.
\newblock In \emph{Acoustics, Speech, and Signal Processing, 1996. ICASSP-96.
  Conference Proceedings., 1996 IEEE International Conference on}, volume~1,
  pages 164--167. IEEE, 1996.

\bibitem[Pascanu et~al.(2013)Pascanu, Mikolov, and
  Bengio]{pascanu2013difficulty}
Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio.
\newblock On the difficulty of training recurrent neural networks.
\newblock \emph{ICML (3)}, 28:\penalty0 1310--1318, 2013.

\bibitem[Pham et~al.(2014)Pham, Bluche, Kermorvant, and
  Louradour]{pham2014dropout}
Vu~Pham, Th{\'e}odore Bluche, Christopher Kermorvant, and J{\'e}r{\^o}me
  Louradour.
\newblock Dropout improves recurrent neural networks for handwriting
  recognition.
\newblock In \emph{Frontiers in Handwriting Recognition (ICFHR), 2014 14th
  International Conference on}, pages 285--290. IEEE, 2014.

\bibitem[Rosenfeld(2000)]{Rosenfeld:2000}
Ronald Rosenfeld.
\newblock Two decades of statistical language modeling: Where do we go from
  here.
\newblock In \emph{Proceedings of the IEEE}, page 2000, 2000.

\bibitem[Rumelhart et~al.(1985)Rumelhart, Hinton, and
  Williams]{rumelhart1985learning}
David~E Rumelhart, Geoffrey~E Hinton, and Ronald~J Williams.
\newblock Learning internal representations by error propagation.
\newblock Technical report, DTIC Document, 1985.

\bibitem[Sag et~al.(2002)Sag, Baldwin, Bond, Copestake, and
  Flickinger]{sag2002multiword}
Ivan~A Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger.
\newblock Multiword expressions: A pain in the neck for nlp.
\newblock In \emph{International Conference on Intelligent Text Processing and
  Computational Linguistics}, pages 1--15. Springer, 2002.

\bibitem[Schwenk(2007)]{schwenk2007continuous}
Holger Schwenk.
\newblock Continuous space language models.
\newblock \emph{Computer Speech \& Language}, 21\penalty0 (3):\penalty0
  492--518, 2007.

\bibitem[Serre et~al.(2007)Serre, Wolf, Bileschi, Riesenhuber, and
  Poggio]{serre2007robust}
Thomas Serre, Lior Wolf, Stanley Bileschi, Maximilian Riesenhuber, and Tomaso
  Poggio.
\newblock Robust object recognition with cortex-like mechanisms.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 29\penalty0 (3):\penalty0 411--426, 2007.

\bibitem[Shen et~al.(2014)Shen, He, Gao, Deng, and Mesnil]{shen2014latent}
Yelong Shen, Xiaodong He, Jianfeng Gao, Li~Deng, and Gr{\'e}goire Mesnil.
\newblock A latent semantic model with convolutional-pooling structure for
  information retrieval.
\newblock In \emph{Proceedings of the 23rd ACM International Conference on
  Conference on Information and Knowledge Management}, pages 101--110. ACM,
  2014.

\bibitem[Simonyan and Zisserman(2014)]{karen2014vgg}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Nitish Srivastava, Geoffrey~E Hinton, Alex Krizhevsky, Ilya Sutskever, and
  Ruslan Salakhutdinov.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\bibitem[Srivastava et~al.(2015)Srivastava, Greff, and
  Schmidhuber]{srivastava2015highway}
Rupesh~Kumar Srivastava, Klaus Greff, and J{\"{u}}rgen Schmidhuber.
\newblock Highway networks.
\newblock \emph{CoRR}, abs/1505.00387, 2015.
\newblock URL \url{http://arxiv.org/abs/1505.00387}.

\bibitem[Sukhbaatar et~al.(2015)Sukhbaatar, Weston, Fergus,
  et~al.]{sukhbaatar2015end}
Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et~al.
\newblock End-to-end memory networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2431--2439, 2015.

\bibitem[Sutskever et~al.(2014)Sutskever, Vinyals, and
  Le]{sutskever2014sequence}
Ilya Sutskever, Oriol Vinyals, and Quoc~V Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  3104--3112, 2014.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{szegedy2015going}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
  Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1--9, 2015.

\bibitem[Tieleman and Hinton(2012)]{tieleman2012lecture}
Tijmen Tieleman and Geoffrey Hinton.
\newblock Lecture 6.5-rmsprop: Divide the gradient by a running average of its
  recent magnitude.
\newblock \emph{COURSERA: Neural Networks for Machine Learning}, 4\penalty0
  (2), 2012.

\bibitem[Vaswani et~al.(2013)Vaswani, Zhao, Fossum, and
  Chiang]{vaswani2013decoding}
Ashish Vaswani, Yinggong Zhao, Victoria Fossum, and David Chiang.
\newblock Decoding with large-scale neural language models improves
  translation.
\newblock In \emph{EMNLP}, pages 1387--1392. Citeseer, 2013.

\bibitem[Waibel et~al.(1989)Waibel, Hanazawa, Hinton, Shikano, and
  Lang]{waibel1989phoneme}
Alexander Waibel, Toshiyuki Hanazawa, Geoffrey Hinton, Kiyohiro Shikano, and
  Kevin~J Lang.
\newblock Phoneme recognition using time-delay neural networks.
\newblock \emph{Acoustics, Speech and Signal Processing, IEEE Transactions on},
  37\penalty0 (3):\penalty0 328--339, 1989.

\bibitem[Witten and Bell(1991)]{witten1991zero}
Ian~H Witten and Timothy~C Bell.
\newblock The zero-frequency problem: Estimating the probabilities of novel
  events in adaptive text compression.
\newblock \emph{Ieee transactions on information theory}, 37\penalty0
  (4):\penalty0 1085--1094, 1991.

\bibitem[Zaremba(2015)]{zaremba2015empirical}
Wojciech Zaremba.
\newblock An empirical exploration of recurrent network architectures.
\newblock 2015.

\bibitem[Zaremba et~al.(2014)Zaremba, Sutskever, and
  Vinyals]{zaremba2014recurrent}
Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals.
\newblock Recurrent neural network regularization.
\newblock \emph{arXiv preprint arXiv:1409.2329}, 2014.

\bibitem[Zeiler(2012)]{zeiler2012adadelta}
Matthew~D Zeiler.
\newblock Adadelta: an adaptive learning rate method.
\newblock \emph{arXiv preprint arXiv:1212.5701}, 2012.

\end{thebibliography}
